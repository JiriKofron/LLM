# Project Context

## User Preferences
- User runs scripts in a separate terminal
- User prefers to see complete tokenization without using [0] index
- User is learning about LLMs and tokenization

## Project Structure
- `show_token_mappings.py`: Demonstrates token ID mappings for BERT and GPT-2
- `compare_tokenizers.py`: Compares different tokenization approaches
- `requirements.txt`: Project dependencies

## Important Notes
- Always check if user is running scripts in a separate terminal
- Don't assume script execution results
- Wait for user feedback about script output
- Focus on explaining concepts and code rather than execution

## Common Issues to Avoid
- Don't lose context between messages
- Don't assume script execution status
- Don't use [0] index for token IDs unless specifically requested
- Always show complete tokenization information

## Learning Focus
- Understanding tokenization
- Differences between BERT and GPT-2
- How token IDs work
- Subword tokenization
- Potential issues with different tokenization approaches 